# Contents

- [Description](#description)
- [Model Architecture](#model-architecture)
- [Dataset](#dataset)
- [Environment Requirements](#environment-requirements)
- [Script Description](#script-description)
    - [Script and Sample Code](#script-and-sample-code)
    - [Training Process](#training-process)
    - [Evaluation Process](#evaluation-process)
    - [Result](#result)
    - [Inference Process](#inference-process)
        - [Export MindIR](#export-mindir)
        - [Infer on Ascend310](#infer-on-ascend310)
        - [result](#result-2)
- [ModelZoo Homepage](#modelzoo-homepage)

## Description

Molecular Dynamics (MD) is playing an increasingly important role in the research of biology, pharmacy, chemistry, and materials science.  The architecture is based on DeePMD, which using an NN scheme for MD simulations, which overcomes the limitations associated to auxiliary quantities like the symmetry functions or the Coulomb matrix. Each environment contains a number of atoms, whose local coordinates are arranged in a symmetry preserving way following the prescription of the Deep Potential method. According to the atomic position, atomic types and box tensor to construct energy.

Thanks a lot for DeePMD team's help.

[1] Paper: L Zhang, J Han, H Wang, R Car, W E. Deep potential molecular dynamics: a scalable model with the accuracy of quantum mechanics. Physical review letters 120 (14), 143001 (2018).

[2] Paper: H Wang, L Zhang, J Han, W E. DeePMD-kit: A deep learning package for many-body potential energy representation and molecular dynamics. Computer Physics Communications 228, 178-184 (2018).

## Model Architecture

The overall network architecture of MD simulation is show below.

[Link](https://arxiv.org/abs/1707.09571)

## Dataset

Dataset used:  deepmodeling/deepmd-kit/examples/water/data

The data is generated by Quantum Espresso and the input of Quantum Espresso is set manually.

The directory structure of the dataset is as follows:

```text
└─data
    ├─type.raw
    ├─set.000
    │   ├──box.npy
    │   ├──coord.npy
    │   ├──energy.npy
    │   └──force.npy
    ├─set.001
    ├─set.002
    └─set.003
```

In `deepmodeling/deepmd-kit/source`:

- Use `train/DataSystem.py` to get d_coord and atype.
- Use function compute_input_stats in `train/DataSystem.py` to get avg and std.
- Use `op/descrpt_se_a.cc` to get d_nlist and nlist.
- Save d_coord, d_nlist, atype, avg, std and nlist as `Npz` file for inference.

## Environment Requirements

- Hardware (Ascend)
- Framework
    - [MindSpore](https://www.mindspore.cn/install/en)
- For more information, please check the resources below:
    - [MindSpore Tutorials](https://www.mindspore.cn/tutorials/en/master/index.html)
    - [MindSpore Python API](https://www.mindspore.cn/docs/api/en/master/index.html)

## Script Description

### Script and Sample Code

```shell
├── md
    ├── README.md                   # descriptions about MD
    ├── script
    │   ├── eval.sh                 # evaluation script
    ├── src
    │   ├── src
    │       ├── config.py           # Parameter config
    │       ├── moxing_adapter.py   # modelarts device configuration
    │       ├── device_adapter.py   # Device Config
    │       ├── local_adapter.py    # local device config
    │   ├── descriptor.py           # descriptor function
    │   └── network.py              # MD simulation architecture
    └── eval.py                     # evaluation interface
    └── default_config.yaml         # config file
```

### Training Process

To Be Done

### Evaluation Process

After installing MindSpore via the official website, you can start evaluation as follows:

```shell
python eval.py --dataset_path [DATASET_PATH] --checkpoint_path [CHECKPOINT_PATH] --baseline_path [BASELINE_PATH]
```

> checkpoint can be trained by using DeePMD-kit, and convert into the ckpt of MindSpore.

### Result

The infer result：

```text
energy: -29944.03
atom_energy: -94.38766   -94.294426  -94.39194   -94.70758   -94.51311   -94.457954 ...
```

- running on ModelArts
- If you want to train the model on modelarts, you can refer to the [official guidance document] of modelarts (https://support.huaweicloud.com/modelarts/)

```python
#  Example of using distributed training dpn on modelarts :
#  Data set storage method

#  ├── molecular_dynamics_dataset                               # dataset dir
#    ├──baseline.npz                                            # baseline dataset
#    ├──input_tensor.npz                                        # infer input dataset
#    ├──water_md.ckpt                                           # checkpoint

# Choose either a (modify yaml file parameters) or b (modelArts create training job to modify parameters) 。
# Example of using model inference on modelarts
# (1) Place the trained model to the corresponding position of the bucket。
# (2) chocie a or b。
#        a.set "enable_modelarts=True"
#          set "checkpoint_path=/cache/data/water_md.ckpt"
#          set "dataset_path=/cache/data/input_tensor.npz"
#          set "baseline_path=/cache/data/baseline.npz"

#       b. Add "enable_modelarts=True" parameter on the interface of modearts。
#          Set the parameters required by method a on the modelarts interface
#          Note: The path parameter does not need to be quoted

# (3) Set the path of the network configuration file "_config_path=/The path of config in default_config.yaml/"
# (4) Set the code path on the modelarts interface "/path/molecular_dynamics"。
# (5) Set the model's startup file on the modelarts interface "eval.py" 。
# (6) Set the data path of the model on the modelarts interface ".../molecular_dynamics"(choices molecular_dynamics Folder path) ,
# The output path of the model "Output file path" and the log path of the model "Job log path"  。
# (7) Start model inference。
```

## Inference Process

### [Export MindIR](#contents)

Export MindIR on local

```shell
python export.py --checkpoint_path [CKPT_PATH] --file_name [FILE_NAME] --file_format [FILE_FORMAT] --config_path [CONFIG_PATH]
```

The `checkpoint_path` parameter is required,
`FILE_FORMAT` should be in ["AIR", "MINDIR"].
> If the model specifications need to be adjusted during export, please modify the corresponding parameters in the `export.py` file at first.

### result

Inference result is saved in current path, you can find result like this in acc.log file.

## ModelZoo Homepage

Please check the official [homepage](https://gitee.com/mindspore/models).
